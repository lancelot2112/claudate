# PyTorch Service Configuration

# Service Settings
PYTORCH_SERVICE_PORT=8001
PYTORCH_MODEL_CACHE_DIR=./model_cache
PYTORCH_MAX_MODELS=3

# Hardware Settings
PYTORCH_CUDA_DEVICE=0
# PYTORCH_CUDA_DEVICE=cpu  # Use this for CPU-only inference

# Model Settings
PYTORCH_DEFAULT_MODEL=Qwen/Qwen2.5-Coder-7B-Instruct
PYTORCH_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Performance Settings
PYTORCH_REQUEST_TIMEOUT=60000
PYTORCH_HEALTH_CHECK_INTERVAL=30000

# Logging
LOG_LEVEL=INFO

# Hugging Face Settings (optional)
# HF_TOKEN=your_huggingface_token  # For private models
# HF_HOME=/app/model_cache  # Cache directory for HF models